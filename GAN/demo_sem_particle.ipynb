{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成低分辨图像数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "# # 定义一个插值方法的列表\n",
    "# methods = [Image.NEAREST, Image.BOX, Image.BILINEAR, Image.HAMMING, Image.BICUBIC, Image.LANCZOS]\n",
    "\n",
    "# # 定义源文件夹和目标文件夹\n",
    "# src_dir = '/home/cxmd/文档/data_for_AI_train/Particles/hr'\n",
    "# dst_dir = '/home/cxmd/文档/data_for_AI_train/Particles/lr'\n",
    "\n",
    "# # 遍历源文件夹中的所有文件\n",
    "# for filename in os.listdir(src_dir):\n",
    "#     # 检查文件是否为jpg文件\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         # 打开图像\n",
    "#         img = Image.open(os.path.join(src_dir, filename))\n",
    "\n",
    "#         # 获取图像的尺寸\n",
    "#         width, height = img.size\n",
    "\n",
    "#         # 计算新的尺寸（这里我们将图像的宽度和高度都减半）\n",
    "#         new_width = width // 2\n",
    "#         new_height = height // 2\n",
    "\n",
    "#         # 随机选择一个插值方法\n",
    "#         method = random.choice(methods)\n",
    "\n",
    "#         # 使用选定的插值方法进行下采样\n",
    "#         low_res_img = img.resize((new_width, new_height), method)\n",
    "\n",
    "#         # 保存低分辨率图像\n",
    "#         low_res_img.save(os.path.join(dst_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = os.listdir(img_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image.to(device)  # 将数据移动到GPU上\n",
    "\n",
    "# 定义转换操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((768, 1024)),  # 将所有图像调整为相同的大小\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 定义源文件夹\n",
    "hr_dir = '/home/cxmd/文档/data_for_AI_train/Particles/hr'\n",
    "lr_dir = '/home/cxmd/文档/data_for_AI_train/Particles/lr'\n",
    "\n",
    "# 加载数据\n",
    "hr_dataset = CustomImageDataset(hr_dir, transform=transform)\n",
    "lr_dataset = CustomImageDataset(lr_dir, transform=transform)\n",
    "\n",
    "# 计算训练集和测试集的大小\n",
    "train_size = int(0.9 * len(hr_dataset))\n",
    "test_size = len(hr_dataset) - train_size\n",
    "\n",
    "# 分割数据集\n",
    "hr_train_dataset, hr_test_dataset = random_split(hr_dataset, [train_size, test_size])\n",
    "lr_train_dataset, lr_test_dataset = random_split(lr_dataset, [train_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "hr_train_loader = torch.utils.data.DataLoader(hr_train_dataset, batch_size=1, shuffle=True)\n",
    "hr_test_loader = torch.utils.data.DataLoader(hr_test_dataset, batch_size=1, shuffle=True)\n",
    "lr_train_loader = torch.utils.data.DataLoader(lr_train_dataset, batch_size=1, shuffle=True)\n",
    "lr_test_loader = torch.utils.data.DataLoader(lr_test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # 这个卷积块包含两个卷积层，每个卷积层后面都跟着一个批量归一化层和一个PReLU激活函数\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在前向传播过程中，我们将输入x和卷积块的输出相加，这就是所谓的\"残差\"连接\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_features, scale_factor):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "\n",
    "        # 这个卷积层将输入的通道数增加到in_features * scale_factor ** 2\n",
    "        self.conv = nn.Conv2d(in_features, in_features * scale_factor ** 2, kernel_size=3, stride=1, padding=1)\n",
    "        # PixelShuffle层用于重新排列卷积层输出的通道，实现上采样\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "        # PReLU激活函数\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        upsample_block_num = int(math.log(scale_factor, 2))\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "        # 第一个卷积块\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        # 残差块\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        # 第二个卷积块\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        # 上采样块\n",
    "        block4 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
    "        block4.append(nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4))\n",
    "        self.block4 = nn.Sequential(*block4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        block4 = self.block4(block1 + block3)\n",
    "\n",
    "        # 使用tanh激活函数将输出限制在[0, 1]范围内\n",
    "        return (torch.tanh(block4) + 1) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 判别器的第一部分是一系列的卷积层，每个卷积层后面都跟着一个LeakyReLU激活函数\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        # 添加一个自适应平均池化层\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((16, 16))\n",
    "\n",
    "        # 判别器的第二部分是一个全连接层，用于将卷积层的输出转换为一个单一的预测值\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*16*16, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)  # 添加这一行\n",
    "        print(x.shape)  # 打印卷积层的输出大小\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "G = Generator(scale_factor=2).to(device)  # 请根据你的需求设置scale_factor的值\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 定义优化器\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 16, 16])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 454.00 MiB is free. Process 3043 has 145.32 MiB memory in use. Including non-PyTorch memory, this process has 9.88 GiB memory in use. Of the allocated memory 9.08 GiB is allocated by PyTorch, and 41.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m hr_fake \u001b[39m=\u001b[39m G(lr_real)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# 计算生成器的损失\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m G_loss \u001b[39m=\u001b[39m criterion(D(hr_fake), torch\u001b[39m.\u001b[39mones_like(D(hr_fake)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# 更新生成器的参数\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m G_optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb 单元格 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)  \u001b[39m# 添加这一行\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cxmd/Nutstore_Files/test_files/neural_network/GAN/demo.ipynb#X21sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)  \u001b[39m# 打印卷积层的输出大小\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/activation.py:774\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 774\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:1646\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu_(\u001b[39minput\u001b[39m, negative_slope)\n\u001b[1;32m   1645\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1646\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[1;32m   1647\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 454.00 MiB is free. Process 3043 has 145.32 MiB memory in use. Including non-PyTorch memory, this process has 9.88 GiB memory in use. Of the allocated memory 9.08 GiB is allocated by PyTorch, and 41.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 定义训练的轮数\n",
    "epochs = 100\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epochs):\n",
    "    for i, (hr_real, lr_real) in enumerate(zip(hr_train_loader, lr_train_loader)):\n",
    "        # 将数据移动到GPU上\n",
    "        hr_real = hr_real.to(device)\n",
    "        lr_real = lr_real.to(device)\n",
    "\n",
    "        # 生成假的高分辨率图像\n",
    "        hr_fake = G(lr_real)\n",
    "\n",
    "        # 计算生成器的损失\n",
    "        G_loss = criterion(D(hr_fake), torch.ones_like(D(hr_fake)))\n",
    "\n",
    "        # 更新生成器的参数\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        # 计算判别器的损失\n",
    "        D_loss_real = criterion(D(hr_real), torch.ones_like(D(hr_real)))\n",
    "        D_loss_fake = criterion(D(hr_fake.detach()), torch.zeros_like(D(hr_fake)))\n",
    "        D_loss = (D_loss_real + D_loss_fake) / 2\n",
    "\n",
    "        # 更新判别器的参数\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "    # 打印损失\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], G_Loss: {G_loss.item()}, D_Loss: {D_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
