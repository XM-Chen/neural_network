{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        output = self.model(z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): BatchNorm1d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear = Linear()\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # 主路径\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels, stride),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "\n",
    "        # 残差路径（shortcut或skip connection）\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.LeakyReLU(inplace=True)(self.main(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ResidualBlock(100, 128),\n",
    "            ResidualBlock(128, 64),\n",
    "            ResidualBlock(64, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        output = self.model(z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-5, 5, 0.001).to(device)\n",
    "y = torch.tanh(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
