{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2f50ab7d790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 为再现性设置随机seem\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # 如果你想要新的结果就是要这段代码\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "# 数据集的根目录\n",
    "dataroot = \"D:\\\\datasets\\\\img_align_celeba\"\n",
    "\n",
    "# 加载数据的工作线程数\n",
    "workers = 2\n",
    "\n",
    "# 训练期间的batch大小\n",
    "batch_size = 128\n",
    "\n",
    "# 训练图像的空间大小。所有图像将使用变压器调整为此大小。\n",
    "image_size = 64\n",
    "\n",
    "# 训练图像中的通道数。对于彩色图像，这是3\n",
    "nc = 3\n",
    "\n",
    "# 潜在向量 z 的大小(例如： 生成器输入的大小)\n",
    "nz = 100\n",
    "\n",
    "# 生成器中特征图的大小\n",
    "ngf = 64\n",
    "\n",
    "# 判别器中的特征映射的大小\n",
    "ndf = 64\n",
    "\n",
    "# 训练epochs的大小\n",
    "num_epochs = 5\n",
    "\n",
    "# 优化器的学习速率\n",
    "lr = 0.0002\n",
    "\n",
    "# 适用于Adam优化器的Beta1超级参数\n",
    "beta1 = 0.5\n",
    "\n",
    "# 可用的GPU数量。使用0表示CPU模式。\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in D:\\datasets\\img_align_celeba.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Nutstore_Files\\test_files\\neural_network\\DCGAN\\demo3.ipynb 单元格 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 创建数据集\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m dset\u001b[39m.\u001b[39;49mImageFolder(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     root\u001b[39m=\u001b[39;49mdataroot,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     transform\u001b[39m=\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mCompose(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         [\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             transforms\u001b[39m.\u001b[39;49mResize(image_size),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             transforms\u001b[39m.\u001b[39;49mCenterCrop(image_size),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             transforms\u001b[39m.\u001b[39;49mToTensor(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             transforms\u001b[39m.\u001b[39;49mNormalize((\u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m), (\u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, \u001b[39m0.5\u001b[39;49m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# 创建加载器\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39mworkers\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Nutstore_Files/test_files/neural_network/DCGAN/demo3.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[1;32me:\\mamba\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32me:\\mamba\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32me:\\mamba\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32me:\\mamba\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in D:\\datasets\\img_align_celeba."
     ]
    }
   ],
   "source": [
    "# 创建数据集\n",
    "dataset = dset.ImageFolder(\n",
    "    root=dataroot,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "# 创建加载器\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=workers\n",
    ")\n",
    "\n",
    "# 选择我们运行在上面的设备\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# 绘制部分我们的输入图像\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(\n",
    "            real_batch[0].to(device)[:64], padding=2, normalize=True\n",
    "        ).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
